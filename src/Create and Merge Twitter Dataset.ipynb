{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05dc8e4",
   "metadata": {},
   "source": [
    "### Process Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441991d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import preprocessor as preprocessor_model\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39458d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_data(file_path, number_of_files):\n",
    "    dfs = []\n",
    "    for i in range(0,number_of_files,1):\n",
    "        fp = file_path + str(i) + '.csv'\n",
    "        print('Processing {}'.format(fp))\n",
    "        tweet_details_df = pd.read_csv(fp)\n",
    "        dates = tweet_details_df.date.tolist()\n",
    "        dates = map(lambda x: x.split(' ')[0], dates)\n",
    "        tweets = tweet_details_df.tweet.tolist()\n",
    "        df = pd.DataFrame({'Date': dates,\n",
    "                           'Tweet':tweets})\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_dfs(dfs):\n",
    "    dates = []\n",
    "    tweets = []\n",
    "    for df in dfs:\n",
    "        print(\"Adding data for {}\".format(df.Date.tolist()[0].split('-')[0]))\n",
    "        dates.extend(df.Date.tolist())\n",
    "        tweets.extend(df.Tweet.tolist())\n",
    "    df = pd.DataFrame({'Date': dates,\n",
    "                           'Tweet':tweets})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c58f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    sentiment_model = SentimentIntensityAnalyzer()\n",
    "    score = sentiment_model.polarity_scores(tweet)['compound']\n",
    "    return score\n",
    "\n",
    "def get_cleaned_text(text):\n",
    "    cleaned_text = preprocessor_model.clean(text)\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd26622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_sentiment(stock_df, sentiment_df):\n",
    "    \n",
    "    stock_dates = stock_df.Date.tolist()\n",
    "    sentiment_dates = sentiment_df.Date.tolist()\n",
    "    sentiment_scores = sentiment_df['Sentiment Score'].tolist()\n",
    "    \n",
    "    sentiment_dict = dict(zip(sentiment_dates, sentiment_scores))\n",
    "    \n",
    "    stock_sentiment_scores = []\n",
    "    for i in range(len(stock_dates)):\n",
    "        if stock_dates[i] in sentiment_dict:\n",
    "            stock_sentiment_scores.append(sentiment_dict[stock_dates[i]])\n",
    "        else:\n",
    "            stock_sentiment_scores.append(np.nan)\n",
    "\n",
    "    complete_sentiment_df = pd.DataFrame({'Date':stock_dates,\n",
    "                                          'Sentiment Score':stock_sentiment_scores})\n",
    "\n",
    "    complete_sentiment_df.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "    complete_sentiment_df.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "    \n",
    "    return complete_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20227887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(stocks_path, tweets_path, number_of_files, save_path):\n",
    "    dfs = restrict_data(tweets_path, number_of_files)\n",
    "\n",
    "    concatenated_df = concatenate_dfs(dfs)\n",
    "\n",
    "    concatenated_df['Cleaned Tweet'] = list(map(get_cleaned_text, concatenated_df['Tweet'].tolist()))\n",
    "    concatenated_df['Sentiment Score'] = list(map(get_sentiment, concatenated_df['Cleaned Tweet'].tolist()))\n",
    "\n",
    "    sentiment_df = concatenated_df[['Date', 'Sentiment Score']]\n",
    "    sentiment_df = sentiment_df.groupby(['Date'], as_index=False).mean()\n",
    "    \n",
    "    stock_df = pd.read_csv(stocks_path)\n",
    "\n",
    "    print('Interpolating Sentiment Scores')\n",
    "    complete_sentiment_df = interpolate_sentiment(stock_df, sentiment_df)\n",
    "\n",
    "    stock_sentiment_df = stock_df\n",
    "    stock_sentiment_df[\"Sentiment Score\"] = complete_sentiment_df[\"Sentiment Score\"]\n",
    "    \n",
    "    print(\"Sample of Data - \\n\\n{}\\n\\n\".format(stock_sentiment_df.head()))\n",
    "    \n",
    "    print('Writing Data to CSV - {}'.format(save_path))\n",
    "    stock_sentiment_df.to_csv(save_path, encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1e95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_path = \"data/processed_dataset/Bound_TSLA.csv\"\n",
    "tweets_path = 'data/raw/Elon_Musk_tweets/201'\n",
    "number_of_files = 10\n",
    "save_path = \"data/processed_dataset/dataset_p1.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372b2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/raw/Elon_Musk_tweets/2010.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2011.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2012.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2013.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2014.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2015.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2016.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2017.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2018.csv\n",
      "Processing data/raw/Elon_Musk_tweets/2019.csv\n",
      "Adding data for 2010\n",
      "Adding data for 2011\n",
      "Adding data for 2012\n",
      "Adding data for 2013\n",
      "Adding data for 2014\n",
      "Adding data for 2015\n",
      "Adding data for 2016\n",
      "Adding data for 2017\n",
      "Adding data for 2018\n",
      "Adding data for 2019\n",
      "Interpolating Sentiment Scores\n",
      "Sample of Data - \n",
      "\n",
      "         Date       Open   High        Low      Close  Adj Close    Volume  \\\n",
      "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300   \n",
      "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100   \n",
      "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800   \n",
      "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800   \n",
      "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900   \n",
      "\n",
      "   Sentiment Score  \n",
      "0           0.4134  \n",
      "1           0.4134  \n",
      "2           0.4134  \n",
      "3           0.4134  \n",
      "4           0.4134  \n",
      "\n",
      "\n",
      "Writing Data to CSV - data/processed_dataset/dataset_p1.csv\n"
     ]
    }
   ],
   "source": [
    "create_dataset(stocks_path, tweets_path, number_of_files, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a63b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
